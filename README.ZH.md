# LCA 检索领域向量（Embedding）微调与评测

本项目聚焦一个问题：在生命周期评价（LCA）这类专业语料的检索任务中，领域化的向量微调能带来多大收益？

## 背景与目标

通用向量模型在开放领域表现良好，但在 LCA 场景中往往会出现“语义相近但不满足领域约束”的错排；而 LCA 文档通常较长、字段多（地理/技术路径/时间等），对检索排序与覆盖提出更强的领域一致性要求。本项目通过统一评测对比，量化领域微调相对通用基线与云端模型的效果差异。

## 数据规模（本次实验）

- 训练集：17,037 条 query-doc
- 评测集：1,893 queries / 3,786 corpus / 1,893 qrels

## 对比设置（概览）

对比对象包括：

- `raw`：`Qwen3-Embedding-0.6B`（通用嵌入基线）
- `ft`：在 LCA 数据上微调后的 `Qwen3-Embedding-0.6B`
- 云端对照：`qwen3-embedding-8b` / `qwen3-embedding-4b`、`bge-m3`、`codestral-embed-2505`

## 指标与结果要点

- 指标：NDCG / MAP / Recall / Precision / MRR @ `{1,5,10,50,100}`（查询级平均）
- 结论：`ft` 相对 `raw` 在头部排序与长尾覆盖上均有显著提升

## 模型效果（摘要）

- 相对 `raw`，`ft` 显著提升：NDCG@10 +31.2%，Recall@10 +25.7%，MRR@10 +33.5%；Recall@100 +11.5%。

## 结论

在本次 LCA 检索评测中，领域化向量微调相对通用基线在排序质量与覆盖度上都带来了明确收益，表明“通用向量 + 领域对齐”是专业检索场景的高性价比路径。

## 许可

- [MIT LICENSE](LICENSE)

## 链接与引用（占位）

- arXiv：TBA
- 引用格式：TBA
- Hugging Face：TBA
- Ollama：TBA
